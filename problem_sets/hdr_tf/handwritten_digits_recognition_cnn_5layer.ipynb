{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-5ebf64bdf178>:21: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting model_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting model_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting model_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting model_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "HI\n",
      "WARNING:tensorflow:From <ipython-input-1-5ebf64bdf178>:116: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Iter 128, Minibatch Loss= 35768.312500, Training Accuracy= 18.75000 %\n",
      "Iter 256, Minibatch Loss= 30267.425781, Training Accuracy= 21.87500 %\n",
      "Iter 384, Minibatch Loss= 24533.121094, Training Accuracy= 26.56250 %\n",
      "Iter 512, Minibatch Loss= 19147.093750, Training Accuracy= 32.03125 %\n",
      "Iter 640, Minibatch Loss= 20815.410156, Training Accuracy= 29.68750 %\n",
      "Iter 768, Minibatch Loss= 19102.234375, Training Accuracy= 26.56250 %\n",
      "Iter 896, Minibatch Loss= 20595.271484, Training Accuracy= 25.78125 %\n",
      "Iter 1024, Minibatch Loss= 17157.203125, Training Accuracy= 23.43750 %\n",
      "Iter 1152, Minibatch Loss= 13799.996094, Training Accuracy= 35.93750 %\n",
      "Iter 1280, Minibatch Loss= 9772.052734, Training Accuracy= 45.31250 %\n",
      "Iter 1408, Minibatch Loss= 12604.724609, Training Accuracy= 39.84375 %\n",
      "Iter 1536, Minibatch Loss= 12256.048828, Training Accuracy= 36.71875 %\n",
      "Iter 1664, Minibatch Loss= 10085.462891, Training Accuracy= 46.87500 %\n",
      "Iter 1792, Minibatch Loss= 10049.988281, Training Accuracy= 45.31250 %\n",
      "Iter 1920, Minibatch Loss= 10147.503906, Training Accuracy= 48.43750 %\n",
      "Iter 2048, Minibatch Loss= 6919.115234, Training Accuracy= 52.34375 %\n",
      "Iter 2176, Minibatch Loss= 11220.990234, Training Accuracy= 50.00000 %\n",
      "Iter 2304, Minibatch Loss= 7394.427734, Training Accuracy= 61.71875 %\n",
      "Iter 2432, Minibatch Loss= 5217.609375, Training Accuracy= 62.50000 %\n",
      "Iter 2560, Minibatch Loss= 6047.459473, Training Accuracy= 56.25000 %\n",
      "Iter 2688, Minibatch Loss= 6392.811035, Training Accuracy= 62.50000 %\n",
      "Iter 2816, Minibatch Loss= 5076.480469, Training Accuracy= 63.28125 %\n",
      "Iter 2944, Minibatch Loss= 4097.065430, Training Accuracy= 65.62500 %\n",
      "Iter 3072, Minibatch Loss= 3887.705078, Training Accuracy= 74.21875 %\n",
      "Iter 3200, Minibatch Loss= 6932.665039, Training Accuracy= 64.06250 %\n",
      "Iter 3328, Minibatch Loss= 5523.783203, Training Accuracy= 70.31250 %\n",
      "Iter 3456, Minibatch Loss= 5041.395508, Training Accuracy= 67.18750 %\n",
      "Iter 3584, Minibatch Loss= 5246.101562, Training Accuracy= 66.40625 %\n",
      "Iter 3712, Minibatch Loss= 4504.690430, Training Accuracy= 69.53125 %\n",
      "Iter 3840, Minibatch Loss= 3340.438965, Training Accuracy= 73.43750 %\n",
      "Iter 3968, Minibatch Loss= 5216.614258, Training Accuracy= 63.28125 %\n",
      "Iter 4096, Minibatch Loss= 4817.110840, Training Accuracy= 70.31250 %\n",
      "Iter 4224, Minibatch Loss= 4900.293945, Training Accuracy= 69.53125 %\n",
      "Iter 4352, Minibatch Loss= 3060.552246, Training Accuracy= 72.65625 %\n",
      "Iter 4480, Minibatch Loss= 4276.206055, Training Accuracy= 70.31250 %\n",
      "Iter 4608, Minibatch Loss= 3562.281494, Training Accuracy= 76.56250 %\n",
      "Iter 4736, Minibatch Loss= 4407.782715, Training Accuracy= 71.09375 %\n",
      "Iter 4864, Minibatch Loss= 4677.560547, Training Accuracy= 72.65625 %\n",
      "Iter 4992, Minibatch Loss= 3064.868652, Training Accuracy= 78.90625 %\n",
      "Iter 5120, Minibatch Loss= 4194.994629, Training Accuracy= 74.21875 %\n",
      "Iter 5248, Minibatch Loss= 2897.735352, Training Accuracy= 81.25000 %\n",
      "Iter 5376, Minibatch Loss= 3661.087402, Training Accuracy= 75.78125 %\n",
      "Iter 5504, Minibatch Loss= 3839.754395, Training Accuracy= 75.00000 %\n",
      "Iter 5632, Minibatch Loss= 3560.958496, Training Accuracy= 77.34375 %\n",
      "Iter 5760, Minibatch Loss= 3489.453613, Training Accuracy= 75.00000 %\n",
      "Iter 5888, Minibatch Loss= 2726.125000, Training Accuracy= 79.68750 %\n",
      "Iter 6016, Minibatch Loss= 3315.260986, Training Accuracy= 74.21875 %\n",
      "Iter 6144, Minibatch Loss= 3393.487793, Training Accuracy= 78.12500 %\n",
      "Iter 6272, Minibatch Loss= 3278.441406, Training Accuracy= 79.68750 %\n",
      "Iter 6400, Minibatch Loss= 2557.545410, Training Accuracy= 82.81250 %\n",
      "Iter 6528, Minibatch Loss= 2760.551514, Training Accuracy= 71.87500 %\n",
      "Iter 6656, Minibatch Loss= 2924.381348, Training Accuracy= 77.34375 %\n",
      "Iter 6784, Minibatch Loss= 1619.581787, Training Accuracy= 83.59375 %\n",
      "Iter 6912, Minibatch Loss= 1951.802002, Training Accuracy= 83.59375 %\n",
      "Iter 7040, Minibatch Loss= 2966.860840, Training Accuracy= 77.34375 %\n",
      "Iter 7168, Minibatch Loss= 1457.855103, Training Accuracy= 85.15625 %\n",
      "Iter 7296, Minibatch Loss= 2596.120605, Training Accuracy= 83.59375 %\n",
      "Iter 7424, Minibatch Loss= 3172.847168, Training Accuracy= 77.34375 %\n",
      "Iter 7552, Minibatch Loss= 3334.869629, Training Accuracy= 79.68750 %\n",
      "Iter 7680, Minibatch Loss= 1389.901978, Training Accuracy= 86.71875 %\n",
      "Iter 7808, Minibatch Loss= 2170.654785, Training Accuracy= 81.25000 %\n",
      "Iter 7936, Minibatch Loss= 2073.944336, Training Accuracy= 81.25000 %\n",
      "Iter 8064, Minibatch Loss= 3330.898682, Training Accuracy= 78.12500 %\n",
      "Iter 8192, Minibatch Loss= 3267.345215, Training Accuracy= 79.68750 %\n",
      "Iter 8320, Minibatch Loss= 3278.380127, Training Accuracy= 80.46875 %\n",
      "Iter 8448, Minibatch Loss= 3052.965820, Training Accuracy= 79.68750 %\n",
      "Iter 8576, Minibatch Loss= 2496.660645, Training Accuracy= 85.15625 %\n",
      "Iter 8704, Minibatch Loss= 3010.738770, Training Accuracy= 80.46875 %\n",
      "Iter 8832, Minibatch Loss= 2020.226685, Training Accuracy= 83.59375 %\n",
      "Iter 8960, Minibatch Loss= 1342.663452, Training Accuracy= 87.50000 %\n",
      "Iter 9088, Minibatch Loss= 2994.883545, Training Accuracy= 85.15625 %\n",
      "Iter 9216, Minibatch Loss= 3566.748291, Training Accuracy= 78.12500 %\n",
      "Iter 9344, Minibatch Loss= 2178.724365, Training Accuracy= 83.59375 %\n",
      "Iter 9472, Minibatch Loss= 2136.921631, Training Accuracy= 80.46875 %\n",
      "Iter 9600, Minibatch Loss= 1471.546143, Training Accuracy= 83.59375 %\n",
      "Iter 9728, Minibatch Loss= 2707.978760, Training Accuracy= 80.46875 %\n",
      "Iter 9856, Minibatch Loss= 2474.487549, Training Accuracy= 82.81250 %\n",
      "Iter 9984, Minibatch Loss= 2297.504395, Training Accuracy= 83.59375 %\n",
      "Iter 10112, Minibatch Loss= 2857.991211, Training Accuracy= 77.34375 %\n",
      "Iter 10240, Minibatch Loss= 2925.244629, Training Accuracy= 80.46875 %\n",
      "Iter 10368, Minibatch Loss= 1535.170410, Training Accuracy= 82.03125 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10496, Minibatch Loss= 1537.576660, Training Accuracy= 86.71875 %\n",
      "Iter 10624, Minibatch Loss= 2534.583984, Training Accuracy= 80.46875 %\n",
      "Iter 10752, Minibatch Loss= 2169.167480, Training Accuracy= 86.71875 %\n",
      "Iter 10880, Minibatch Loss= 1652.381348, Training Accuracy= 85.15625 %\n",
      "Iter 11008, Minibatch Loss= 2079.388184, Training Accuracy= 85.93750 %\n",
      "Iter 11136, Minibatch Loss= 1523.394897, Training Accuracy= 89.06250 %\n",
      "Iter 11264, Minibatch Loss= 2289.893066, Training Accuracy= 80.46875 %\n",
      "Iter 11392, Minibatch Loss= 2339.970215, Training Accuracy= 86.71875 %\n",
      "Iter 11520, Minibatch Loss= 1496.336914, Training Accuracy= 88.28125 %\n",
      "Iter 11648, Minibatch Loss= 2462.299805, Training Accuracy= 80.46875 %\n",
      "Iter 11776, Minibatch Loss= 1911.314575, Training Accuracy= 87.50000 %\n",
      "Iter 11904, Minibatch Loss= 2513.520996, Training Accuracy= 84.37500 %\n",
      "Iter 12032, Minibatch Loss= 2185.581055, Training Accuracy= 81.25000 %\n",
      "Iter 12160, Minibatch Loss= 958.216797, Training Accuracy= 88.28125 %\n",
      "Iter 12288, Minibatch Loss= 1447.855469, Training Accuracy= 85.15625 %\n",
      "Iter 12416, Minibatch Loss= 672.679321, Training Accuracy= 93.75000 %\n",
      "Iter 12544, Minibatch Loss= 1553.561768, Training Accuracy= 85.93750 %\n",
      "Iter 12672, Minibatch Loss= 2916.513184, Training Accuracy= 81.25000 %\n",
      "Iter 12800, Minibatch Loss= 2376.790527, Training Accuracy= 85.93750 %\n",
      "Iter 12928, Minibatch Loss= 2053.446777, Training Accuracy= 84.37500 %\n",
      "Iter 13056, Minibatch Loss= 1169.135986, Training Accuracy= 91.40625 %\n",
      "Iter 13184, Minibatch Loss= 2709.136475, Training Accuracy= 82.03125 %\n",
      "Iter 13312, Minibatch Loss= 1373.593628, Training Accuracy= 85.15625 %\n",
      "Iter 13440, Minibatch Loss= 1171.364014, Training Accuracy= 85.93750 %\n",
      "Iter 13568, Minibatch Loss= 1717.962158, Training Accuracy= 85.15625 %\n",
      "Iter 13696, Minibatch Loss= 1543.573730, Training Accuracy= 85.15625 %\n",
      "Iter 13824, Minibatch Loss= 1943.575073, Training Accuracy= 86.71875 %\n",
      "Iter 13952, Minibatch Loss= 979.747192, Training Accuracy= 91.40625 %\n",
      "Iter 14080, Minibatch Loss= 375.882965, Training Accuracy= 93.75000 %\n",
      "Iter 14208, Minibatch Loss= 1017.599426, Training Accuracy= 92.18750 %\n",
      "Iter 14336, Minibatch Loss= 1864.062500, Training Accuracy= 83.59375 %\n",
      "Iter 14464, Minibatch Loss= 1840.926025, Training Accuracy= 88.28125 %\n",
      "Iter 14592, Minibatch Loss= 1841.102295, Training Accuracy= 85.93750 %\n",
      "Iter 14720, Minibatch Loss= 841.441711, Training Accuracy= 86.71875 %\n",
      "Iter 14848, Minibatch Loss= 1416.185303, Training Accuracy= 88.28125 %\n",
      "Iter 14976, Minibatch Loss= 890.067749, Training Accuracy= 86.71875 %\n",
      "Iter 15104, Minibatch Loss= 1629.748901, Training Accuracy= 87.50000 %\n",
      "Iter 15232, Minibatch Loss= 1041.523193, Training Accuracy= 90.62500 %\n",
      "Iter 15360, Minibatch Loss= 1469.025757, Training Accuracy= 87.50000 %\n",
      "Iter 15488, Minibatch Loss= 2166.406250, Training Accuracy= 84.37500 %\n",
      "Iter 15616, Minibatch Loss= 830.601807, Training Accuracy= 85.93750 %\n",
      "Iter 15744, Minibatch Loss= 2483.776855, Training Accuracy= 84.37500 %\n",
      "Iter 15872, Minibatch Loss= 2938.253418, Training Accuracy= 78.12500 %\n",
      "Iter 16000, Minibatch Loss= 1708.178223, Training Accuracy= 86.71875 %\n",
      "Iter 16128, Minibatch Loss= 1069.283203, Training Accuracy= 92.96875 %\n",
      "Iter 16256, Minibatch Loss= 886.733398, Training Accuracy= 89.06250 %\n",
      "Iter 16384, Minibatch Loss= 2338.800781, Training Accuracy= 82.03125 %\n",
      "Iter 16512, Minibatch Loss= 2255.618164, Training Accuracy= 81.25000 %\n",
      "Iter 16640, Minibatch Loss= 2533.828613, Training Accuracy= 86.71875 %\n",
      "Iter 16768, Minibatch Loss= 1462.659546, Training Accuracy= 87.50000 %\n",
      "Iter 16896, Minibatch Loss= 1908.659058, Training Accuracy= 84.37500 %\n",
      "Iter 17024, Minibatch Loss= 2839.867676, Training Accuracy= 84.37500 %\n",
      "Iter 17152, Minibatch Loss= 628.398621, Training Accuracy= 92.18750 %\n",
      "Iter 17280, Minibatch Loss= 1149.750366, Training Accuracy= 92.18750 %\n",
      "Iter 17408, Minibatch Loss= 279.308472, Training Accuracy= 96.87500 %\n",
      "Iter 17536, Minibatch Loss= 1162.922852, Training Accuracy= 89.84375 %\n",
      "Iter 17664, Minibatch Loss= 1250.949219, Training Accuracy= 89.84375 %\n",
      "Iter 17792, Minibatch Loss= 1383.042969, Training Accuracy= 85.93750 %\n",
      "Iter 17920, Minibatch Loss= 1881.181885, Training Accuracy= 83.59375 %\n",
      "Iter 18048, Minibatch Loss= 985.039429, Training Accuracy= 89.84375 %\n",
      "Iter 18176, Minibatch Loss= 815.932312, Training Accuracy= 87.50000 %\n",
      "Iter 18304, Minibatch Loss= 2161.663574, Training Accuracy= 86.71875 %\n",
      "Iter 18432, Minibatch Loss= 1504.749756, Training Accuracy= 88.28125 %\n",
      "Iter 18560, Minibatch Loss= 1366.077393, Training Accuracy= 86.71875 %\n",
      "Iter 18688, Minibatch Loss= 1673.758789, Training Accuracy= 85.15625 %\n",
      "Iter 18816, Minibatch Loss= 1896.708252, Training Accuracy= 79.68750 %\n",
      "Iter 18944, Minibatch Loss= 2007.693604, Training Accuracy= 79.68750 %\n",
      "Iter 19072, Minibatch Loss= 2412.043457, Training Accuracy= 85.93750 %\n",
      "Iter 19200, Minibatch Loss= 1588.792969, Training Accuracy= 89.84375 %\n",
      "Iter 19328, Minibatch Loss= 802.713806, Training Accuracy= 89.84375 %\n",
      "Iter 19456, Minibatch Loss= 1494.369507, Training Accuracy= 85.93750 %\n",
      "Iter 19584, Minibatch Loss= 1584.284790, Training Accuracy= 88.28125 %\n",
      "Iter 19712, Minibatch Loss= 1190.394531, Training Accuracy= 91.40625 %\n",
      "Iter 19840, Minibatch Loss= 1371.860596, Training Accuracy= 88.28125 %\n",
      "Iter 19968, Minibatch Loss= 1352.214478, Training Accuracy= 86.71875 %\n",
      "Iter 20096, Minibatch Loss= 945.647705, Training Accuracy= 89.06250 %\n",
      "Iter 20224, Minibatch Loss= 1077.735107, Training Accuracy= 89.06250 %\n",
      "Iter 20352, Minibatch Loss= 1186.739502, Training Accuracy= 90.62500 %\n",
      "Iter 20480, Minibatch Loss= 1539.512329, Training Accuracy= 85.15625 %\n",
      "Iter 20608, Minibatch Loss= 2420.724121, Training Accuracy= 81.25000 %\n",
      "Iter 20736, Minibatch Loss= 2358.333740, Training Accuracy= 86.71875 %\n",
      "Iter 20864, Minibatch Loss= 2170.951416, Training Accuracy= 85.93750 %\n",
      "Iter 20992, Minibatch Loss= 922.499329, Training Accuracy= 87.50000 %\n",
      "Iter 21120, Minibatch Loss= 2565.109131, Training Accuracy= 85.15625 %\n",
      "Iter 21248, Minibatch Loss= 1588.942383, Training Accuracy= 87.50000 %\n",
      "Iter 21376, Minibatch Loss= 708.373779, Training Accuracy= 91.40625 %\n",
      "Iter 21504, Minibatch Loss= 1261.925049, Training Accuracy= 85.93750 %\n",
      "Iter 21632, Minibatch Loss= 807.089966, Training Accuracy= 89.84375 %\n",
      "Iter 21760, Minibatch Loss= 749.069397, Training Accuracy= 91.40625 %\n",
      "Iter 21888, Minibatch Loss= 1650.013184, Training Accuracy= 87.50000 %\n",
      "Iter 22016, Minibatch Loss= 607.532898, Training Accuracy= 92.96875 %\n",
      "Iter 22144, Minibatch Loss= 1126.206299, Training Accuracy= 87.50000 %\n",
      "Iter 22272, Minibatch Loss= 1286.277588, Training Accuracy= 92.18750 %\n",
      "Iter 22400, Minibatch Loss= 1087.479004, Training Accuracy= 85.93750 %\n",
      "Iter 22528, Minibatch Loss= 509.549927, Training Accuracy= 94.53125 %\n",
      "Iter 22656, Minibatch Loss= 486.630768, Training Accuracy= 92.18750 %\n",
      "Iter 22784, Minibatch Loss= 1227.312256, Training Accuracy= 89.06250 %\n",
      "Iter 22912, Minibatch Loss= 1120.470825, Training Accuracy= 91.40625 %\n",
      "Iter 23040, Minibatch Loss= 1026.801514, Training Accuracy= 87.50000 %\n",
      "Iter 23168, Minibatch Loss= 1820.634033, Training Accuracy= 85.15625 %\n",
      "Iter 23296, Minibatch Loss= 1346.832520, Training Accuracy= 89.06250 %\n",
      "Iter 23424, Minibatch Loss= 743.209290, Training Accuracy= 91.40625 %\n",
      "Iter 23552, Minibatch Loss= 1148.648560, Training Accuracy= 88.28125 %\n",
      "Iter 23680, Minibatch Loss= 1751.833618, Training Accuracy= 85.93750 %\n",
      "Iter 23808, Minibatch Loss= 694.138855, Training Accuracy= 92.96875 %\n",
      "Iter 23936, Minibatch Loss= 800.803833, Training Accuracy= 92.18750 %\n",
      "Iter 24064, Minibatch Loss= 1425.295166, Training Accuracy= 89.06250 %\n",
      "Iter 24192, Minibatch Loss= 1590.879150, Training Accuracy= 87.50000 %\n",
      "Iter 24320, Minibatch Loss= 1161.371460, Training Accuracy= 91.40625 %\n",
      "Iter 24448, Minibatch Loss= 704.099670, Training Accuracy= 92.18750 %\n",
      "Iter 24576, Minibatch Loss= 948.848572, Training Accuracy= 89.06250 %\n",
      "Iter 24704, Minibatch Loss= 1934.591187, Training Accuracy= 87.50000 %\n",
      "Iter 24832, Minibatch Loss= 2021.405884, Training Accuracy= 84.37500 %\n",
      "Iter 24960, Minibatch Loss= 2166.658203, Training Accuracy= 82.03125 %\n",
      "Iter 25088, Minibatch Loss= 1662.786621, Training Accuracy= 84.37500 %\n",
      "Iter 25216, Minibatch Loss= 839.446411, Training Accuracy= 91.40625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 25344, Minibatch Loss= 1240.623901, Training Accuracy= 90.62500 %\n",
      "Iter 25472, Minibatch Loss= 1232.274536, Training Accuracy= 84.37500 %\n",
      "Iter 25600, Minibatch Loss= 1114.026367, Training Accuracy= 87.50000 %\n",
      "Iter 25728, Minibatch Loss= 1725.227051, Training Accuracy= 84.37500 %\n",
      "Iter 25856, Minibatch Loss= 1046.946167, Training Accuracy= 85.93750 %\n",
      "Iter 25984, Minibatch Loss= 1548.967407, Training Accuracy= 85.93750 %\n",
      "Iter 26112, Minibatch Loss= 742.365662, Training Accuracy= 92.18750 %\n",
      "Iter 26240, Minibatch Loss= 1868.934692, Training Accuracy= 84.37500 %\n",
      "Iter 26368, Minibatch Loss= 1603.966919, Training Accuracy= 86.71875 %\n",
      "Iter 26496, Minibatch Loss= 1251.406372, Training Accuracy= 89.84375 %\n",
      "Iter 26624, Minibatch Loss= 1730.447510, Training Accuracy= 86.71875 %\n",
      "Iter 26752, Minibatch Loss= 1137.102417, Training Accuracy= 90.62500 %\n",
      "Iter 26880, Minibatch Loss= 1243.958618, Training Accuracy= 86.71875 %\n",
      "Iter 27008, Minibatch Loss= 1190.584839, Training Accuracy= 90.62500 %\n",
      "Iter 27136, Minibatch Loss= 2577.260742, Training Accuracy= 85.93750 %\n",
      "Iter 27264, Minibatch Loss= 937.208252, Training Accuracy= 92.18750 %\n",
      "Iter 27392, Minibatch Loss= 630.474976, Training Accuracy= 93.75000 %\n",
      "Iter 27520, Minibatch Loss= 1041.223633, Training Accuracy= 89.84375 %\n",
      "Iter 27648, Minibatch Loss= 974.963501, Training Accuracy= 88.28125 %\n",
      "Iter 27776, Minibatch Loss= 1276.693848, Training Accuracy= 89.06250 %\n",
      "Iter 27904, Minibatch Loss= 895.105469, Training Accuracy= 89.84375 %\n",
      "Iter 28032, Minibatch Loss= 627.010620, Training Accuracy= 93.75000 %\n",
      "Iter 28160, Minibatch Loss= 1042.471680, Training Accuracy= 87.50000 %\n",
      "Iter 28288, Minibatch Loss= 558.663940, Training Accuracy= 92.96875 %\n",
      "Iter 28416, Minibatch Loss= 745.364136, Training Accuracy= 91.40625 %\n",
      "Iter 28544, Minibatch Loss= 1108.054199, Training Accuracy= 86.71875 %\n",
      "Iter 28672, Minibatch Loss= 1850.226196, Training Accuracy= 87.50000 %\n",
      "Iter 28800, Minibatch Loss= 1491.277588, Training Accuracy= 89.06250 %\n",
      "Iter 28928, Minibatch Loss= 1112.897949, Training Accuracy= 92.18750 %\n",
      "Iter 29056, Minibatch Loss= 1779.869629, Training Accuracy= 86.71875 %\n",
      "Iter 29184, Minibatch Loss= 385.690735, Training Accuracy= 93.75000 %\n",
      "Iter 29312, Minibatch Loss= 1067.296265, Training Accuracy= 91.40625 %\n",
      "Iter 29440, Minibatch Loss= 772.263184, Training Accuracy= 89.06250 %\n",
      "Iter 29568, Minibatch Loss= 1046.042236, Training Accuracy= 89.06250 %\n",
      "Iter 29696, Minibatch Loss= 836.544617, Training Accuracy= 92.18750 %\n",
      "Iter 29824, Minibatch Loss= 1790.567505, Training Accuracy= 87.50000 %\n",
      "Iter 29952, Minibatch Loss= 1399.089600, Training Accuracy= 88.28125 %\n",
      "Iter 30080, Minibatch Loss= 693.068359, Training Accuracy= 96.09375 %\n",
      "Iter 30208, Minibatch Loss= 782.467651, Training Accuracy= 91.40625 %\n",
      "Iter 30336, Minibatch Loss= 745.500000, Training Accuracy= 87.50000 %\n",
      "Iter 30464, Minibatch Loss= 1228.292236, Training Accuracy= 91.40625 %\n",
      "Iter 30592, Minibatch Loss= 968.483215, Training Accuracy= 92.96875 %\n",
      "Iter 30720, Minibatch Loss= 993.389648, Training Accuracy= 92.18750 %\n",
      "Iter 30848, Minibatch Loss= 431.985718, Training Accuracy= 92.96875 %\n",
      "Iter 30976, Minibatch Loss= 526.984924, Training Accuracy= 93.75000 %\n",
      "Iter 31104, Minibatch Loss= 279.343842, Training Accuracy= 92.96875 %\n",
      "Iter 31232, Minibatch Loss= 1510.633789, Training Accuracy= 90.62500 %\n",
      "Iter 31360, Minibatch Loss= 755.537537, Training Accuracy= 90.62500 %\n",
      "Iter 31488, Minibatch Loss= 1642.913452, Training Accuracy= 91.40625 %\n",
      "Iter 31616, Minibatch Loss= 750.380737, Training Accuracy= 92.18750 %\n",
      "Iter 31744, Minibatch Loss= 400.369507, Training Accuracy= 92.18750 %\n",
      "Iter 31872, Minibatch Loss= 1108.500854, Training Accuracy= 89.06250 %\n",
      "Iter 32000, Minibatch Loss= 927.364319, Training Accuracy= 88.28125 %\n",
      "Iter 32128, Minibatch Loss= 1433.441040, Training Accuracy= 92.18750 %\n",
      "Iter 32256, Minibatch Loss= 1166.045654, Training Accuracy= 86.71875 %\n",
      "Iter 32384, Minibatch Loss= 1605.193359, Training Accuracy= 92.96875 %\n",
      "Iter 32512, Minibatch Loss= 1214.281250, Training Accuracy= 92.96875 %\n",
      "Iter 32640, Minibatch Loss= 492.994659, Training Accuracy= 92.96875 %\n",
      "Iter 32768, Minibatch Loss= 748.856079, Training Accuracy= 95.31250 %\n",
      "Iter 32896, Minibatch Loss= 460.891602, Training Accuracy= 93.75000 %\n",
      "Iter 33024, Minibatch Loss= 1163.824951, Training Accuracy= 89.06250 %\n",
      "Iter 33152, Minibatch Loss= 1042.807373, Training Accuracy= 91.40625 %\n",
      "Iter 33280, Minibatch Loss= 1111.819580, Training Accuracy= 90.62500 %\n",
      "Iter 33408, Minibatch Loss= 934.596375, Training Accuracy= 92.96875 %\n",
      "Iter 33536, Minibatch Loss= 1716.625366, Training Accuracy= 90.62500 %\n",
      "Iter 33664, Minibatch Loss= 1418.486206, Training Accuracy= 89.84375 %\n",
      "Iter 33792, Minibatch Loss= 989.929321, Training Accuracy= 94.53125 %\n",
      "Iter 33920, Minibatch Loss= 514.422363, Training Accuracy= 95.31250 %\n",
      "Iter 34048, Minibatch Loss= 1248.627808, Training Accuracy= 91.40625 %\n",
      "Iter 34176, Minibatch Loss= 1430.701660, Training Accuracy= 89.06250 %\n",
      "Iter 34304, Minibatch Loss= 1257.668579, Training Accuracy= 89.06250 %\n",
      "Iter 34432, Minibatch Loss= 934.187622, Training Accuracy= 89.84375 %\n",
      "Iter 34560, Minibatch Loss= 588.205200, Training Accuracy= 89.84375 %\n",
      "Iter 34688, Minibatch Loss= 1068.545288, Training Accuracy= 94.53125 %\n",
      "Iter 34816, Minibatch Loss= 956.200562, Training Accuracy= 91.40625 %\n",
      "Iter 34944, Minibatch Loss= 329.732391, Training Accuracy= 94.53125 %\n",
      "Iter 35072, Minibatch Loss= 1795.961914, Training Accuracy= 89.06250 %\n",
      "Iter 35200, Minibatch Loss= 593.609741, Training Accuracy= 94.53125 %\n",
      "Iter 35328, Minibatch Loss= 899.402344, Training Accuracy= 90.62500 %\n",
      "Iter 35456, Minibatch Loss= 562.463989, Training Accuracy= 94.53125 %\n",
      "Iter 35584, Minibatch Loss= 386.057281, Training Accuracy= 93.75000 %\n",
      "Iter 35712, Minibatch Loss= 856.653748, Training Accuracy= 91.40625 %\n",
      "Iter 35840, Minibatch Loss= 1275.849609, Training Accuracy= 93.75000 %\n",
      "Iter 35968, Minibatch Loss= 1073.447510, Training Accuracy= 90.62500 %\n",
      "Iter 36096, Minibatch Loss= 447.830444, Training Accuracy= 96.09375 %\n",
      "Iter 36224, Minibatch Loss= 1034.048950, Training Accuracy= 92.96875 %\n",
      "Iter 36352, Minibatch Loss= 741.045288, Training Accuracy= 92.96875 %\n",
      "Iter 36480, Minibatch Loss= 673.221863, Training Accuracy= 90.62500 %\n",
      "Iter 36608, Minibatch Loss= 459.318359, Training Accuracy= 92.96875 %\n",
      "Iter 36736, Minibatch Loss= 747.506592, Training Accuracy= 89.84375 %\n",
      "Iter 36864, Minibatch Loss= 694.356445, Training Accuracy= 91.40625 %\n",
      "Iter 36992, Minibatch Loss= 338.801758, Training Accuracy= 92.18750 %\n",
      "Iter 37120, Minibatch Loss= 1041.843994, Training Accuracy= 91.40625 %\n",
      "Iter 37248, Minibatch Loss= 759.626709, Training Accuracy= 89.84375 %\n",
      "Iter 37376, Minibatch Loss= 1240.928467, Training Accuracy= 90.62500 %\n",
      "Iter 37504, Minibatch Loss= 460.049286, Training Accuracy= 92.96875 %\n",
      "Iter 37632, Minibatch Loss= 575.560791, Training Accuracy= 95.31250 %\n",
      "Iter 37760, Minibatch Loss= 919.765503, Training Accuracy= 89.84375 %\n",
      "Iter 37888, Minibatch Loss= 1310.976074, Training Accuracy= 90.62500 %\n",
      "Iter 38016, Minibatch Loss= 1589.796387, Training Accuracy= 89.06250 %\n",
      "Iter 38144, Minibatch Loss= 598.316895, Training Accuracy= 91.40625 %\n",
      "Iter 38272, Minibatch Loss= 658.132935, Training Accuracy= 93.75000 %\n",
      "Iter 38400, Minibatch Loss= 1268.495972, Training Accuracy= 92.18750 %\n",
      "Iter 38528, Minibatch Loss= 225.358032, Training Accuracy= 96.87500 %\n",
      "Iter 38656, Minibatch Loss= 320.905548, Training Accuracy= 92.18750 %\n",
      "Iter 38784, Minibatch Loss= 1446.158813, Training Accuracy= 89.06250 %\n",
      "Iter 38912, Minibatch Loss= 573.715942, Training Accuracy= 92.96875 %\n",
      "Iter 39040, Minibatch Loss= 1122.364014, Training Accuracy= 92.18750 %\n",
      "Iter 39168, Minibatch Loss= 947.739685, Training Accuracy= 89.84375 %\n",
      "Iter 39296, Minibatch Loss= 639.145386, Training Accuracy= 93.75000 %\n",
      "Iter 39424, Minibatch Loss= 1259.875977, Training Accuracy= 90.62500 %\n",
      "Iter 39552, Minibatch Loss= 650.008301, Training Accuracy= 93.75000 %\n",
      "Iter 39680, Minibatch Loss= 949.472534, Training Accuracy= 94.53125 %\n",
      "Iter 39808, Minibatch Loss= 638.132324, Training Accuracy= 95.31250 %\n",
      "Iter 39936, Minibatch Loss= 831.300537, Training Accuracy= 93.75000 %\n",
      "Iter 40064, Minibatch Loss= 918.470581, Training Accuracy= 92.18750 %\n",
      "Iter 40192, Minibatch Loss= 773.930847, Training Accuracy= 92.96875 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40320, Minibatch Loss= 784.258545, Training Accuracy= 94.53125 %\n",
      "Iter 40448, Minibatch Loss= 990.738647, Training Accuracy= 90.62500 %\n",
      "Iter 40576, Minibatch Loss= 415.966370, Training Accuracy= 94.53125 %\n",
      "Iter 40704, Minibatch Loss= 720.035828, Training Accuracy= 94.53125 %\n",
      "Iter 40832, Minibatch Loss= 382.503235, Training Accuracy= 93.75000 %\n",
      "Iter 40960, Minibatch Loss= 510.460205, Training Accuracy= 94.53125 %\n",
      "Iter 41088, Minibatch Loss= 546.823730, Training Accuracy= 92.96875 %\n",
      "Iter 41216, Minibatch Loss= 1117.423218, Training Accuracy= 90.62500 %\n",
      "Iter 41344, Minibatch Loss= 582.747559, Training Accuracy= 92.18750 %\n",
      "Iter 41472, Minibatch Loss= 1276.516479, Training Accuracy= 91.40625 %\n",
      "Iter 41600, Minibatch Loss= 542.097107, Training Accuracy= 93.75000 %\n",
      "Iter 41728, Minibatch Loss= 660.060242, Training Accuracy= 92.96875 %\n",
      "Iter 41856, Minibatch Loss= 665.591980, Training Accuracy= 93.75000 %\n",
      "Iter 41984, Minibatch Loss= 842.329346, Training Accuracy= 91.40625 %\n",
      "Iter 42112, Minibatch Loss= 918.470154, Training Accuracy= 90.62500 %\n",
      "Iter 42240, Minibatch Loss= 657.998047, Training Accuracy= 93.75000 %\n",
      "Iter 42368, Minibatch Loss= 778.116028, Training Accuracy= 91.40625 %\n",
      "Iter 42496, Minibatch Loss= 646.044373, Training Accuracy= 96.09375 %\n",
      "Iter 42624, Minibatch Loss= 789.779663, Training Accuracy= 90.62500 %\n",
      "Iter 42752, Minibatch Loss= 873.188599, Training Accuracy= 90.62500 %\n",
      "Iter 42880, Minibatch Loss= 1098.702393, Training Accuracy= 91.40625 %\n",
      "Iter 43008, Minibatch Loss= 993.465088, Training Accuracy= 89.84375 %\n",
      "Iter 43136, Minibatch Loss= 1056.965332, Training Accuracy= 89.84375 %\n",
      "Iter 43264, Minibatch Loss= 903.510376, Training Accuracy= 93.75000 %\n",
      "Iter 43392, Minibatch Loss= 634.941284, Training Accuracy= 93.75000 %\n",
      "Iter 43520, Minibatch Loss= 1007.646118, Training Accuracy= 90.62500 %\n",
      "Iter 43648, Minibatch Loss= 1291.592773, Training Accuracy= 89.06250 %\n",
      "Iter 43776, Minibatch Loss= 639.829346, Training Accuracy= 94.53125 %\n",
      "Iter 43904, Minibatch Loss= 629.613159, Training Accuracy= 92.18750 %\n",
      "Iter 44032, Minibatch Loss= 1122.263306, Training Accuracy= 91.40625 %\n",
      "Iter 44160, Minibatch Loss= 588.590210, Training Accuracy= 94.53125 %\n",
      "Iter 44288, Minibatch Loss= 630.065369, Training Accuracy= 92.18750 %\n",
      "Iter 44416, Minibatch Loss= 962.857544, Training Accuracy= 93.75000 %\n",
      "Iter 44544, Minibatch Loss= 637.914856, Training Accuracy= 93.75000 %\n",
      "Iter 44672, Minibatch Loss= 1310.975342, Training Accuracy= 90.62500 %\n",
      "Iter 44800, Minibatch Loss= 800.500427, Training Accuracy= 92.18750 %\n",
      "Iter 44928, Minibatch Loss= 1382.881470, Training Accuracy= 89.06250 %\n",
      "Iter 45056, Minibatch Loss= 651.588501, Training Accuracy= 94.53125 %\n",
      "Iter 45184, Minibatch Loss= 183.706528, Training Accuracy= 97.65625 %\n",
      "Iter 45312, Minibatch Loss= 629.024841, Training Accuracy= 95.31250 %\n",
      "Iter 45440, Minibatch Loss= 340.518921, Training Accuracy= 96.09375 %\n",
      "Iter 45568, Minibatch Loss= 677.436584, Training Accuracy= 94.53125 %\n",
      "Iter 45696, Minibatch Loss= 787.480164, Training Accuracy= 90.62500 %\n",
      "Iter 45824, Minibatch Loss= 1170.190674, Training Accuracy= 89.84375 %\n",
      "Iter 45952, Minibatch Loss= 417.721985, Training Accuracy= 94.53125 %\n",
      "Iter 46080, Minibatch Loss= 251.695251, Training Accuracy= 93.75000 %\n",
      "Iter 46208, Minibatch Loss= 559.989502, Training Accuracy= 92.18750 %\n",
      "Iter 46336, Minibatch Loss= 1181.447021, Training Accuracy= 89.06250 %\n",
      "Iter 46464, Minibatch Loss= 530.036255, Training Accuracy= 93.75000 %\n",
      "Iter 46592, Minibatch Loss= 1255.374390, Training Accuracy= 87.50000 %\n",
      "Iter 46720, Minibatch Loss= 653.703308, Training Accuracy= 91.40625 %\n",
      "Iter 46848, Minibatch Loss= 592.802734, Training Accuracy= 92.18750 %\n",
      "Iter 46976, Minibatch Loss= 872.921021, Training Accuracy= 92.96875 %\n",
      "Iter 47104, Minibatch Loss= 327.382538, Training Accuracy= 95.31250 %\n",
      "Iter 47232, Minibatch Loss= 614.384644, Training Accuracy= 91.40625 %\n",
      "Iter 47360, Minibatch Loss= 440.020599, Training Accuracy= 92.96875 %\n",
      "Iter 47488, Minibatch Loss= 457.672363, Training Accuracy= 94.53125 %\n",
      "Iter 47616, Minibatch Loss= 841.525635, Training Accuracy= 93.75000 %\n",
      "Iter 47744, Minibatch Loss= 617.160339, Training Accuracy= 95.31250 %\n",
      "Iter 47872, Minibatch Loss= 905.483154, Training Accuracy= 93.75000 %\n",
      "Iter 48000, Minibatch Loss= 242.762009, Training Accuracy= 93.75000 %\n",
      "Iter 48128, Minibatch Loss= 839.315125, Training Accuracy= 91.40625 %\n",
      "Iter 48256, Minibatch Loss= 339.549072, Training Accuracy= 94.53125 %\n",
      "Iter 48384, Minibatch Loss= 936.740051, Training Accuracy= 89.06250 %\n",
      "Iter 48512, Minibatch Loss= 687.132812, Training Accuracy= 92.96875 %\n",
      "Iter 48640, Minibatch Loss= 613.390015, Training Accuracy= 94.53125 %\n",
      "Iter 48768, Minibatch Loss= 863.874695, Training Accuracy= 90.62500 %\n",
      "Iter 48896, Minibatch Loss= 579.188660, Training Accuracy= 92.18750 %\n",
      "Iter 49024, Minibatch Loss= 639.665161, Training Accuracy= 93.75000 %\n",
      "Iter 49152, Minibatch Loss= 696.036926, Training Accuracy= 89.84375 %\n",
      "Iter 49280, Minibatch Loss= 387.629517, Training Accuracy= 92.18750 %\n",
      "Iter 49408, Minibatch Loss= 493.634094, Training Accuracy= 93.75000 %\n",
      "Iter 49536, Minibatch Loss= 1343.118042, Training Accuracy= 92.96875 %\n",
      "Iter 49664, Minibatch Loss= 838.974243, Training Accuracy= 91.40625 %\n",
      "Iter 49792, Minibatch Loss= 492.251160, Training Accuracy= 90.62500 %\n",
      "Iter 49920, Minibatch Loss= 526.964111, Training Accuracy= 96.09375 %\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 96.09375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Modified version:\n",
    "Kiran Gunnam\n",
    "A Convolutional Network implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('model_data/', one_hot=True)\n",
    "print (\"HI\")\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 1.0 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "\n",
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "def avgpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.avg_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "wt1 = weights['wc1']\n",
    "wt2 = weights['wc2']\n",
    "wd1 = weights['wd1']\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "tf.summary.histogram(\"W1\",wt1 )\n",
    "tf.summary.histogram(\"W1\",wt2 )\n",
    "tf.summary.histogram(\"W1\",wd1 )\n",
    "# Define loss and optimizer\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    tf.summary.scalar(\"cost\",cost)\n",
    "# Evaluate model\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))*100\n",
    "    tf.summary.scalar(\"accuracy\",accuracy)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    writer = tf.summary.FileWriter(\"./logs/cnn_logs2\", sess.graph) # for 0.8\n",
    "    merged = tf.summary.merge_all()\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       keep_prob: dropout})\n",
    "        #if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "        s, loss, acc = sess.run([merged,cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y,\n",
    "                                                          keep_prob: 1.})\n",
    "        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f} %\".format(acc))\n",
    "        writer.add_summary(s, step)\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
