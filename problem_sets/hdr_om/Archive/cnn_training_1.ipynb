{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Error: 78.3639821724 at iteration 0']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy as sypy\n",
    "from scipy import signal\n",
    "from scipy import io\n",
    "\n",
    "maxtrain=6; #maximum training images\n",
    "iter = 1; #maximum iterations\n",
    "eta=0.01; # learning rate\n",
    "\n",
    "n_fl=10;\n",
    "\n",
    "# %%select the pooling\n",
    "# pool='maxpool';\n",
    "pool= 'avgpool';\n",
    "\n",
    "from ipynb.fs.full.cnn import cnnload\n",
    "from ipynb.fs.full.avgpool import avgpool\n",
    "from ipynb.fs.full.avgpool import maxpool\n",
    "\n",
    "trained_parameter_file = 'trained_parameters'+'_maxtrain'+str(maxtrain)+'_iter'+str(iter)+'_eta'+str(eta)+ pool+'.mat';\n",
    "[trainlabels, trainimages, testlabels, testimages] = cnnload()\n",
    "\n",
    "# function defintion here\n",
    "\n",
    "fn = 4;  # number of kernels for layer 1\n",
    "ks = 5;  # size of kernel\n",
    "[n, h, w] = np.shape(trainimages);\n",
    "n = min(n, maxtrain);\n",
    "\n",
    "# normalize data to [-1,1] range\n",
    "nitrain = (trainimages / 255) * 2 - 1;\n",
    "\n",
    "# train with backprop\n",
    "h1 = h - ks + 1;\n",
    "w1 = w - ks + 1;\n",
    "A1 = np.zeros((fn, h1, w1));\n",
    "\n",
    "h2 = int(h1 / 2);\n",
    "w2 = int(w1 / 2);\n",
    "I2 = np.zeros((fn,h2, w2));\n",
    "A2 = np.zeros((fn,h2, w2));\n",
    "A3 = np.zeros(10);\n",
    "\n",
    "# % kernels for layer 1\n",
    "W1 = np.random.randn(fn,ks, ks) * .01;\n",
    "B1 = np.ones(fn);\n",
    "\n",
    "# % scale parameter and bias for layer 2\n",
    "S2 = np.random.randn(1, fn) * .01;\n",
    "B2 = np.ones(fn);\n",
    "\n",
    "# % weights and bias parameters for fully-connected output layer\n",
    "W3 = np.random.randn(10,fn, h2, w2) * .01;\n",
    "B3 = np.ones(10);\n",
    "\n",
    "# % true outputs\n",
    "Y = np.eye(10) * 2 - 1;\n",
    "\n",
    "for it in range(0, iter):\n",
    "    err = 0;\n",
    "    for im in range(0, n):\n",
    "        # ------------ FORWARD PROP ------------%\n",
    "        # ------Layer 1: convolution with bias followed by tanh activation function\n",
    "        for fm in range(0, fn):\n",
    "            A1[fm, :, :,] = sypy.signal.convolve2d(nitrain[im, :, :], W1[fm, ::-1, ::-1], 'valid') + B1[fm];\n",
    "        Z1 = np.tanh(A1)\n",
    "\n",
    "        # ------Layer 2: max or average(both subsample) with scaling and bias\n",
    "\n",
    "        for fm in range(0, fn):\n",
    "            if pool == 'maxpool':\n",
    "                I2[fm, :, :] = maxpool(Z1[fm, :, :])\n",
    "            elif pool == 'avgpool':\n",
    "                I2[fm, :, :] = avgpool(Z1[fm, :, :])\n",
    "            A2[fm, :, :] = I2[fm, :, :] * S2[:,fm] + B2[fm]\n",
    "        Z2 = np.tanh(A2)\n",
    "        # ------Layer 3: fully connected\n",
    "\n",
    "        for cl in range(0, n_fl):\n",
    "            A3[cl] =sypy.signal.convolve(Z2, W3[cl, ::-1, ::-1, :: -1], 'valid') + B3[cl]\n",
    "\n",
    "        Z3 = np.tanh(A3)\n",
    "        err = err + 0.5*lin.norm(Z3.T - Y[:,trainlabels[im]],2)**2\n",
    "\n",
    "        # ------------ BACK PROP ------------%\n",
    "        # -------Compute error at output layer\n",
    "        Del3 = (1 - Z3 ** 2) * (Z3.T - Y[:,trainlabels[im]]);\n",
    "\n",
    "        #---Compute error at layer2\n",
    "        Del2 = np.zeros(np.shape(Z2));\n",
    "        for cl in range(0,10):\n",
    "            Del2 = Del2 + Del3[cl] * W3[cl];\n",
    "\n",
    "        Del2=Del2*(1- Z2**2)\n",
    "\n",
    "        # Compute error at layer1\n",
    "        Del1= np.zeros(np.shape(Z1))\n",
    "        for fm in range(0,fn):\n",
    "            Del1[fm,:,:]=(S2[:,fm]/4)*(1-Z1[fm,:,:]**2)\n",
    "            for ih in range(0,h1):\n",
    "                for iw in range(0,w1):\n",
    "                    Del1[fm,ih,iw]=Del1[fm,ih,iw]*Del2[fm,ih//2,iw//2]\n",
    "        # Update weights at layer3\n",
    "        DB3=Del3\n",
    "        B3=B3 -eta*DB3\n",
    "\n",
    "\n",
    "        for cl in range(0,10):\n",
    "            DW3= DB3[cl] * Z2\n",
    "            W3[3,:,:,:]=W3[cl,:,:,:] -eta*DW3\n",
    "\n",
    "        for fm in range(0,fn):\n",
    "            DS2 = sypy.signal.convolve(Del2[fm,:,:],I2[fm, ::-1, ::-1],'valid')\n",
    "            S2[:,fm]=S2[:,fm] -eta*DS2\n",
    "\n",
    "            DB2=sum(sum(Del2[fm,:,:]))\n",
    "            B2[fm]=B2[fm] -eta*DB2\n",
    "\n",
    "\n",
    "        for fm in range(0,fn):\n",
    "            DW1 = sypy.signal.convolve(nitrain[im,:,:],Del1[fm, ::-1, ::-1],'valid')\n",
    "            W1[fm,:,:]=W1[fm,:,:] -eta*DW1\n",
    "\n",
    "            DB1=sum(sum(Del1[fm,:,:]))\n",
    "            B1[fm]=B1[fm] -eta*DB1\n",
    "    print(['Error: '+str(err)+' at iteration '+ str(it)])\n",
    "sypy.io.savemat(trained_parameter_file,{'W1':W1,'B1':B1,'S2':S2,'B2':B2,'W3':W3,'B3':B3,'maxtrain':maxtrain,'it':it,'eta':eta,'err':err})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(trained_parameter_file,'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77,  65,  84, ..., 122, 132,  63], dtype=uint8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fromstring(file.read(),dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
